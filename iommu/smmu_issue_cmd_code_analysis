smmu arm_smmu_cmdq_issue_cmdlist
================================

-v0.1 2021.5.28 Sherlock init

本文分析Linux kernel SMMU驱动里的arm_smmu_cmdq_issue_cmdlist这个函数。基于v5.12


基本数据结构和函数
------------------

 struct arm_smmu_cmdq的结构是：
   - struct arm_smmu_queue q;     smmu queue的通用数据结构
     - llq                        软件维护的cmdq的produce和comsumer位置
     - base, prod_reg, cons_reg   cmdq的基地址，prod_reg/cons_reg寄存器的地址等
     - ...
   - valid_map                    每一个cmdq entry一个bit的bitmap
   - owner_prod                   用来表示当前拥有smmu的情况？
   - lock                         和sync回绕相关的锁


 READ_ONCE 保证读一次，不被编译器优化。

 cmpxchg_relaxed(*prt, old, new) 这个函数的语义是：当*prt等于old的时候，把new赋值
 给*prt，返回值是old; 当*prt不等于old的时候，不做操作，返回值是*prt。

 atomic_cond_read_relaxed/smp_cond_load_relaxed 前者是后者的一个atomic形式的封装，
 所以，先搞清后者的语义smp_cond_load_relaxed(ptr, cond_expr)；不停的把ptr地址上
 的数据放到VAL里，然后检测cond_expr的条件，如果为真，整体返回，如果是假，就继续
 读ptr的值。所以atomic_cond_read_relaxed(v, c)的语义是反复把v的值读到VAL里，然后
 判断c，如果c为真则返回，如果c是假就继续读。

 atomic_fetch_andnot_relaxed(i, *prt) 把i按位取反后的值和*prt相与，写入*prt。整个
 是一个原子操作。

 atomic_set_release release语义的原子写，姑且先当做原子写。

 atomic_read 原子读。

 atomic_dec_return_release 姑且先看做atomic_dec_return，原子减1，并且返回修改后
 的原子变量的值。

 atomic_fetch_inc_relaxed 姑且先看做原子加1。

 dma_wmb dma写barrier

基本模型
--------

 smmu的这个提交命令的操作搞的这么复杂，主要解决的问题是，多个cpu向一个cmdq一起
 发送请求时遇到的性能问题。这里使用了免锁的实现。函数的对外语义是接受用户发来的
 n个cmd，可以最后带上SYNC，提交到smmu的cmdq。基本的实现方式是，各个调用这个函数
 的用户首先使用无锁的方式抢到自己的cmdq entry坑位; 把命令放到坑位里; 各个用户再
 依次占有硬件，通过写prod寄存器的方式把命令发给硬件。这个过程里，用户可以在自己
 的一串命令后加上SYNC，也可以不加，如果加上SYNC需要处理相关的同步问题。

 下面具体分析代码：
```
	/* 1. Allocate some space in the queue */
	local_irq_save(flags);
	// 取出当前软件维护队列的头尾地址
	llq.val = READ_ONCE(cmdq->q.llq.val);
	do {
		u64 old;

		while (!queue_has_space(&llq, n + sync)) {
			local_irq_restore(flags);
			// 如果cmdq里已经没有足够的空间，那就在此等待
			if (arm_smmu_cmdq_poll_until_not_full(smmu, &llq))
				dev_err_ratelimited(smmu->dev, "CMDQ timeout\n");
			local_irq_save(flags);
		}

		// 如果有空间，构造随后原子覆盖prod域段的临时变量, 并在最新的prod
		// 上把owner的标记加上
		head.cons = llq.cons;
		head.prod = queue_inc_prod_n(&llq, n + sync) |
					     CMDQ_PROD_OWNED_FLAG;

		// llq.val的值是从cmdq->q.llq.val中取出来的，如果依然相等，说明
		// 从取出来到尝试刷新这段时间，没有其他用户去刷新这个值，那么我们
		// 就用我们的新prod/cons原子的更新他，如果不相等，说明有其他的用户
		// 已经在我们前面更新了cmdq->q.llq.va，我们取出最新的值，再此重复
		// 上述过程，直到我们可以抢到坑位。
		//
		// 其实，这里是一个标准的无锁抢占的实现。
		old = cmpxchg_relaxed(&cmdq->q.llq.val, llq.val, head.val);
		if (old == llq.val)
			break;

		llq.val = old;
	} while (1);
	// llq.prod这个位置是当前可以放入cmd的第一个位置。
	//
	//    llq.cons ... llq.prod                     <- 当前队列状态
	//    head.cons ...                head.prod    <- 新写入的队列占用状态
	//
	// 可以看到在上面原子写q.llq.val的时候，把owner的状态带到了head.prod上,
	// 不同的user可以并发的把cmd一段一段的放到cmdq里，但是同一个时间只有一个
	// user可以给smmu发通知，就是写smmu cmdq的prod寄存器，所以不同的user在
	// 写prod寄存器的时候要独占smmu硬件。
	//
	// 下面的这一行是检测其他user有没有放开之前一段cmd entry的占有。如果之前
	// 一段cmd entry已经放开了，我们当前的user就可有占有硬件，随后更新prod
	// 寄存器，如果之前没有放开，我们当前的user就只是把命令放入cmdq(什么时候写入？)
	//
	// llq.prod上的owner flag在如下第4部的b小步骤中清除。
	owner = !(llq.prod & CMDQ_PROD_OWNED_FLAG);
	head.prod &= ~CMDQ_PROD_OWNED_FLAG;
	llq.prod &= ~CMDQ_PROD_OWNED_FLAG;

	/*
	 * 2. Write our commands into the queue
	 * Dependency ordering from the cmpxchg() loop above.
	 */
	arm_smmu_cmdq_write_entries(cmdq, cmds, llq.prod, n);
	if (sync) {
		prod = queue_inc_prod_n(&llq, n);
		arm_smmu_cmdq_build_sync_cmd(cmd_sync, smmu, prod);
		queue_write(Q_ENT(&cmdq->q, prod), cmd_sync, CMDQ_ENT_DWORDS);

		// 没有搞清楚这里？
		/*
		 * In order to determine completion of our CMD_SYNC, we must
		 * ensure that the queue can't wrap twice without us noticing.
		 * We achieve that by taking the cmdq lock as shared before
		 * marking our slot as valid.
		 */
		arm_smmu_cmdq_shared_lock(cmdq);
	}

	/* 3. Mark our slots as valid, ensuring commands are visible first */
	// 这个barrier没有搞清楚？
	dma_wmb();
	// 在valid_map上，把llq.prod - head.prod的对应bit置成valid
	arm_smmu_cmdq_set_valid_map(cmdq, llq.prod, head.prod);

	/* 4. If we are the owner, take control of the SMMU hardware */
	if (owner) {
		// 这里是等之前的写prod已经做了，其他的user在写了prod后，会把他
		// 当前的prod值写入到cmdq->owner_prod，这里就是在一直检测这个值。
		// 之前一个prod就是llq.prod。
		/* a. Wait for previous owner to finish */
		atomic_cond_read_relaxed(&cmdq->owner_prod, VAL == llq.prod);

		// 原子的清除掉当前user prod上的owner flag
		/* b. Stop gathering work by clearing the owned flag */
		prod = atomic_fetch_andnot_relaxed(CMDQ_PROD_OWNED_FLAG,
						   &cmdq->q.llq.atomic.prod);
		prod &= ~CMDQ_PROD_OWNED_FLAG;

		// 等待其他的user在上面第三部把相应的valid bit置上。
		/*
		 * c. Wait for any gathered work to be written to the queue.
		 * Note that we read our own entries so that we have the control
		 * dependency required by (d).
		 */
		arm_smmu_cmdq_poll_valid_map(cmdq, llq.prod, prod);

		/*
		 * d. Advance the hardware prod pointer
		 * Control dependency ordering from the entries becoming valid.
		 */
		writel_relaxed(prod, cmdq->q.prod_reg);

		/*
		 * e. Tell the next owner we're done
		 * Make sure we've updated the hardware first, so that we don't
		 * race to update prod and potentially move it backwards.
		 */
		atomic_set_release(&cmdq->owner_prod, prod);
	}

	/* 5. If we are inserting a CMD_SYNC, we must wait for it to complete */
	if (sync) {
		llq.prod = queue_inc_prod_n(&llq, n);
		// 等SYNC命令之前的命令完成，smmu提供了两种方式，一种是MSI，一种
		// SEV。虽然协议上说可以搞一个MSI中断，但是这里的实现是把SYNC命令
		// 占用的cmdq entry的地址写到SYNC命令自己的MSI address域段，MSI data
		// 域段写了0，这样当SYNC命令完成的时候，SYNC命令的第32bit会被清零。
		// SEV的方式使用wfe指令的把CPU放到低功耗模式，SYNC命令完成时会唤醒
		// CPU，因为wfe还有其他的唤醒方式(中断，sev指令)，所以在wfe醒来
		// 之后执行的代码里，会去循环检测cmdq cons寄存器，SMMU的语义保证
		// cons更新可见时，前面的命令都已经完成。
		//
		ret = arm_smmu_cmdq_poll_until_sync(smmu, &llq);
		if (ret) {
			dev_err_ratelimited(smmu->dev,
					    "CMD_SYNC timeout at 0x%08x [hwprod 0x%08x, hwcons 0x%08x]\n",
					    llq.prod,
					    readl_relaxed(cmdq->q.prod_reg),
					    readl_relaxed(cmdq->q.cons_reg));
		}

		// 同上，不清楚这里为啥要锁？
		/*
		 * Try to unlock the cmdq lock. This will fail if we're the last
		 * reader, in which case we can safely update cmdq->q.llq.cons
		 */
		if (!arm_smmu_cmdq_shared_tryunlock(cmdq)) {
			WRITE_ONCE(cmdq->q.llq.cons, llq.cons);
			arm_smmu_cmdq_shared_unlock(cmdq);
		}
	}

	local_irq_restore(flags);
```
